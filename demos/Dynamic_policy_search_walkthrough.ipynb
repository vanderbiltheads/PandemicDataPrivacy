{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dynamic Policy Search Walkthrough\n",
    "\n",
    "This notebook demonstrates how we use the privacy risk estimation framework to identify acceptable policies - according to a user-defined privacy risk threshold and tolerance level - at varying quantities of disease case patient records. This walkthrough searches the policy space according to the estimated PK risk. Searching the space per the estimated marketer risk takes an identical approach, replacing the PK risk estimation component with the marketer risk estimation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load libraries\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data\n",
    "Since the user defines the case count thresholds, we do not need case counts data. For the privacy risk estimation, however, we still need each counties demographic joint statistics. We use the example census data here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fips</th>\n",
       "      <th>age</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>ethnicity</th>\n",
       "      <th>counts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>w</td>\n",
       "      <td>Male</td>\n",
       "      <td>hl</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>w</td>\n",
       "      <td>Male</td>\n",
       "      <td>hl</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>w</td>\n",
       "      <td>Male</td>\n",
       "      <td>hl</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>w</td>\n",
       "      <td>Male</td>\n",
       "      <td>hl</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>w</td>\n",
       "      <td>Male</td>\n",
       "      <td>hl</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28835</th>\n",
       "      <td>10</td>\n",
       "      <td>98</td>\n",
       "      <td>mixed</td>\n",
       "      <td>Female</td>\n",
       "      <td>nh</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28836</th>\n",
       "      <td>10</td>\n",
       "      <td>99</td>\n",
       "      <td>mixed</td>\n",
       "      <td>Female</td>\n",
       "      <td>nh</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28837</th>\n",
       "      <td>10</td>\n",
       "      <td>100</td>\n",
       "      <td>mixed</td>\n",
       "      <td>Female</td>\n",
       "      <td>nh</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28838</th>\n",
       "      <td>10</td>\n",
       "      <td>105</td>\n",
       "      <td>mixed</td>\n",
       "      <td>Female</td>\n",
       "      <td>nh</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28839</th>\n",
       "      <td>10</td>\n",
       "      <td>110</td>\n",
       "      <td>mixed</td>\n",
       "      <td>Female</td>\n",
       "      <td>nh</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>28840 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       fips  age   race     sex ethnicity  counts\n",
       "0         1    0      w    Male        hl       8\n",
       "1         1    1      w    Male        hl       6\n",
       "2         1    2      w    Male        hl       7\n",
       "3         1    3      w    Male        hl       6\n",
       "4         1    4      w    Male        hl       9\n",
       "...     ...  ...    ...     ...       ...     ...\n",
       "28835    10   98  mixed  Female        nh       4\n",
       "28836    10   99  mixed  Female        nh       3\n",
       "28837    10  100  mixed  Female        nh      18\n",
       "28838    10  105  mixed  Female        nh       0\n",
       "28839    10  110  mixed  Female        nh       5\n",
       "\n",
       "[28840 rows x 6 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import census data\n",
    "\n",
    "census = pd.read_csv(\"example_census_data.csv\")\n",
    "census"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code\n",
    "We again use the generalize helper function and the privacy_risk_estimation_PK class for the search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generalize(df, ind_col = \"fips\", ages = False, races = False, sexes = False, ethnicities = False):\n",
    "    \"\"\"\n",
    "    Generalizes census data for age, race, sex, and/or ethnicity.\n",
    "    \"\"\"\n",
    "    temp = df.copy()\n",
    "    \n",
    "    if ages:\n",
    "        temp['age'] = pd.cut(temp['age'],ages, right=False) \n",
    "    if races:\n",
    "        for race_gen in races:\n",
    "            for key, value in race_gen.items():\n",
    "                for val in value:\n",
    "                    temp.loc[temp.race == val, 'race'] = key         \n",
    "    if sexes:\n",
    "        temp['sex'] = 'both_sex'\n",
    "    if ethnicities == 1:\n",
    "        temp['ethnicity'] = 'both_ethnicity'\n",
    "        \n",
    "    new_temp = temp.groupby([ind_col, 'sex', 'race', 'age', 'ethnicity'])\\\n",
    "                    .agg({'counts':'sum'})\\\n",
    "                    .astype({'counts':int}).reset_index()\n",
    "    \n",
    "    new_temp['bins'] = new_temp['sex'] + ',' + \\\n",
    "                        new_temp['race'] + ',' + \\\n",
    "                        new_temp['ethnicity'] + ',' + \\\n",
    "                        new_temp['age'].astype(str)\n",
    "    \n",
    "    return new_temp.pivot_table(index = ind_col, columns = 'bins', values = 'counts')\n",
    "\n",
    "\n",
    "class privacy_risk_estimation_PK:\n",
    "    \n",
    "    \"\"\"\n",
    "    Uses Monte Carlo sampling techniques (without replacement) to estimate the longitudinal PK risk\n",
    "    of a sharing patient-level pandemic data on a consistent basis (e.g., daily or weekly)\n",
    "    for a user-specified k value. The PK risk is estimated for each time point in a given county,\n",
    "    when sharing data under a specific data sharing policy (which defines the demographic bins). \n",
    "    The PK risk values are calculated on a lagged period of infected individuals.\n",
    "    \n",
    "    Input:\n",
    "    counts = Dataframe of the case counts per time period (e.g. daily counts of new disease cases from\n",
    "             the JHU COVID-19 surveillance data). Must include the fips code in the index and the columns\n",
    "             must be date values.\n",
    "    gen_census = The generalized census, i.e., the output of the generalize function above for the\n",
    "                 specified fips code.\n",
    "    fips = The fips code of interest. Must be of the same format of the counts dataframe index column.\n",
    "    n_sims = The number of simulations to be run in the experiment.\n",
    "    k = The k value to be used in the PK risk calculation. Default is 10.\n",
    "    period_size = The size of the lagging period to be used for calculating the PK risk values.\n",
    "                  Default value is 3.\n",
    "    \n",
    "    Output:\n",
    "    self.PK = Dataframe where each row is a unique simulation and each column is a time period. Each cell\n",
    "              value corresponds to the proportion of infected individuals who fall into a demographic\n",
    "              bins of size k or less. The self.PK values are calculated from a lagged period of\n",
    "              individuals, whose size is specified by period_size. For example, if period_size = 3 and\n",
    "              the dataset is updated daily, the PK risk value on a given day in a given simulation is \n",
    "              the proportion of infected individuals from the day and the previous two days who fall into a \n",
    "              demographic bins of size k or less.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, counts, gen_census, fips, n_sims, k=10, period_size=3, rng=np.random.default_rng()):\n",
    "        \n",
    "        self.counts = counts.loc[fips,:].values\n",
    "        self.dates = counts.columns\n",
    "        self.census = gen_census\n",
    "        self.n_bins = len(self.census)\n",
    "        self.PK = pd.DataFrame(columns = self.dates)\n",
    "        self.n_sims = n_sims\n",
    "        self.xk = np.arange(self.n_sims)\n",
    "        self.k = k\n",
    "        self.period_size = period_size\n",
    "        self.recent_cases = []\n",
    "        self.rng = rng\n",
    "        \n",
    "    def create_full_population(self):\n",
    "        \n",
    "        \"\"\"\n",
    "        Creates full population from generalized census counts.\n",
    "        \"\"\"\n",
    "        \n",
    "        self.full_pop = np.tile(self.census.values, (self.n_sims,1))\n",
    "        \n",
    "    def get_infected_population(self):\n",
    "        \n",
    "        \"\"\"\n",
    "        Creates the infected population for each simulation.\n",
    "        \"\"\"\n",
    "        \n",
    "        ppl = self.full_pop[0]\n",
    "        self.indexed_pop = np.concatenate(list(map(lambda i: np.repeat(i, ppl[i]), range(len(ppl)))),axis=0)\n",
    "        \n",
    "        # if more than one equivalence class, randomly choose infected from full population\n",
    "        if len(self.full_pop[0]) > 1:\n",
    "            self.choose_infected()\n",
    "        else:\n",
    "            self.choose_infected(False)\n",
    "        \n",
    "    def choose_infected(self, true_shuffle=True):\n",
    "        \n",
    "        \"\"\"\n",
    "        Monte Carlo random samples without replacement the infected indviduals from the population.\n",
    "        \"\"\"\n",
    "        \n",
    "        total_ppl = self.counts.sum()\n",
    "        \n",
    "        if true_shuffle:\n",
    "            self.infected = np.stack(list(map(lambda sim: self.rng.choice(self.indexed_pop,\n",
    "                                                                          size=total_ppl,\n",
    "                                                                          replace=False),\n",
    "                                         range(self.n_sims))), axis=0)\n",
    "        else:\n",
    "            row = self.indexed_pop[:total_ppl]\n",
    "            self.infected = np.tile(row, (self.n_sims, 1))\n",
    "            \n",
    "        #del self.indexed_pop\n",
    "    \n",
    "    def count_per_bin(self):\n",
    "            \n",
    "        \"\"\"\n",
    "        Counts the number of infected individuals in each demographic bin for the current time\n",
    "        period's infections.\n",
    "        \"\"\"\n",
    "        \n",
    "        # empty array for the time period's newest per bin per simulation\n",
    "        self.new_cases = np.zeros((self.n_sims, self.n_bins))\n",
    "        \n",
    "        # split shuffled values on sample size\n",
    "        samples, self.infected = np.split(self.infected, [self.n_ppl], axis=1)\n",
    "        \n",
    "        # add infected people per bin\n",
    "        for i in samples.T:\n",
    "            self.new_cases[self.xk,i] += 1\n",
    "    \n",
    "    def drop_frame(self):\n",
    "        \n",
    "        \"\"\"\n",
    "        Removes the oldest set of infections from recent cases.\n",
    "        \"\"\"\n",
    "        \n",
    "        self.recent_cases.pop(0)\n",
    "        \n",
    "    def add_frame(self):\n",
    "        \n",
    "        \"\"\"\n",
    "        Adds the newest set of infections to recent cases.\n",
    "        \"\"\"\n",
    "        \n",
    "        self.recent_cases.append(self.new_cases)\n",
    "    \n",
    "    def update_recent_cases(self):\n",
    "        \n",
    "        \"\"\"\n",
    "        Updates the list of recent cases reported within the lagging period.\n",
    "        \"\"\"\n",
    "        \n",
    "        if len(self.recent_cases) == self.period_size:\n",
    "            self.drop_frame()\n",
    "            self.add_frame()\n",
    "        else:\n",
    "            self.add_frame()\n",
    "        self.get_cases_in_period()\n",
    "        \n",
    "    def get_cases_in_period(self):\n",
    "        \n",
    "        \"\"\"\n",
    "        Sums the number of reported cases in each demographic bin with a diagnosis date within\n",
    "        the lagging period.\n",
    "        \"\"\"\n",
    "        \n",
    "        self.cases_in_period = sum(self.recent_cases)\n",
    "    \n",
    "    def calc_PK_risk(self):\n",
    "        \n",
    "        \"\"\"\n",
    "        Calculates the PK risk on the cases reported in the lagging period.\n",
    "        \"\"\"\n",
    "        \n",
    "        n_ppl = self.cases_in_period.sum(axis=1)[0]\n",
    "        if n_ppl == 0:\n",
    "            return [0] * self.n_sims\n",
    "        else:\n",
    "            risk = np.ndarray((self.n_sims, self.k))\n",
    "            for i in range(1, self.k+1):\n",
    "                risk[:,(i-1)] = np.count_nonzero(self.cases_in_period == i, axis=1) * i\n",
    "            return risk.sum(axis=1)/n_ppl\n",
    "        \n",
    "    def run_full_simulation(self):\n",
    "        \"\"\"\n",
    "        Runs the full simulation.\n",
    "        \"\"\"\n",
    "        self.create_full_population()\n",
    "        self.get_infected_population()\n",
    "        \n",
    "        fill_zeros = True\n",
    "        \n",
    "        for i in range(len(self.dates)):\n",
    "            date = self.dates[i]\n",
    "            self.n_ppl = self.counts[i]\n",
    "            \n",
    "            if fill_zeros:\n",
    "                if (self.n_ppl == 0):\n",
    "                    self.PK[date] = [0] * self.n_sims\n",
    "                else:\n",
    "                    self.count_per_bin()\n",
    "                    self.update_recent_cases()\n",
    "                    self.PK[date] = self.calc_PK_risk()\n",
    "                    fill_zeros = False\n",
    "                \n",
    "            else:\n",
    "                self.count_per_bin()\n",
    "                self.update_recent_cases()\n",
    "                self.PK[date] = self.calc_PK_risk()\n",
    "        \n",
    "    def get_stats(self, df, percentiles):\n",
    "        \n",
    "        \"\"\"\n",
    "        Helper function to generate summary statistics on the simulation results.\n",
    "        \"\"\"\n",
    "        \n",
    "        stats = np.percentile(df, percentiles, axis=0)\n",
    "        results = pd.DataFrame()\n",
    "        results['date'] = self.dates\n",
    "        results['lower'] = stats[0, :]\n",
    "        results['mean'] = np.mean(df, axis=0).values\n",
    "        results['upper'] = stats[1, :]\n",
    "\n",
    "        return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We next define the dynamic_policy_search_PK class. This class search a policy space according to user-defined quasi-identifier generalization hierarchies, k value for the PK risk calculation, PK risk threshold, and the percentile used to compare the privacy risk distribution from the Monte Carlo simulations to the PK risk threshold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class dynamic_policy_search_PK:\n",
    "    \n",
    "    \"\"\"\n",
    "    Searches the policy space for those that meet the PK risk threshold for each of the counties in\n",
    "    a total population range.\n",
    "    \n",
    "    Input:\n",
    "    age_hier = Dictionary of age generalization hierarchy, where keys are the numerical levels of the hierarcy\n",
    "               and the values are the parameters to be passed to the generalization helper function. Key 0\n",
    "               must correspond to the most generalized level in the hierarchy.\n",
    "    age_name = Dictionary of the name convention for each level of the age generalization hierarchy. The keys\n",
    "               should match those of the age_hierarchy, where the values are the named value.\n",
    "    race_hier = Dictionary of race generalization hierarchy.\n",
    "    race_name = Dictionary of race generalization names.\n",
    "    sex_hier = Dictionary of sex generalization hierarchy.\n",
    "    sex_name = Dictionary of sex generalization names.\n",
    "    ethnicity_hier = Dictionary of ethnicity generalization hierarchy.\n",
    "    ethnicity_name = Dictionary of ethnicity generalization names.\n",
    "    census = Dataframe of the census tract information for each county. Columns include fips code, race,\n",
    "             age, sex, counts, and ethnicity.\n",
    "    pop_lower_bound = Integer defining the lower bound of the county population range. The range defines\n",
    "                      which counties are used in generating the privcacy risk estimates.\n",
    "    pop_upper_bound = Integer defining the upper bound of the county population range.\n",
    "    threshold = PK risk threshold.\n",
    "    percent = Percentile used to compare the PK risk estimates to the PK risk threshold. For \n",
    "              example, if the upper bound of the 95% quantile range is used for the comparison, percent\n",
    "              should be 97.5.\n",
    "    num_simulations = Integer defining the number of simulations run in each county's PK risk estimates.\n",
    "    caseloads = List of monotonically increasing numbers, defining the case record thresholds at which\n",
    "                each policy is evaluted. For the PK risk, these numbers represent the total number of\n",
    "                case records in the dataset.\n",
    "    k = k value used in PK risk calculation.\n",
    "    repeat = Boolean value. If True, the search will consider all policies for each case count threshold.\n",
    "             If False, the search will remove policies that previously met the privacy risk threshold at \n",
    "             lower case counts when testing higher case counts.\n",
    "    \n",
    "                \n",
    "    Output:\n",
    "    results = Dictionary of the policy search results. The keys are the integers from caseloads. The dictionary\n",
    "              values are the named policies that meet the PK risk threshold for all counties (with a total\n",
    "              population in the defined range) when the total number of disease case records is at least the value\n",
    "              of the corresponding key.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, age_hier, age_name, race_hier, race_name, sex_hier, sex_name, ethnicity_hier,\n",
    "                 ethnicity_name, census, pop_lower_bound, pop_upper_bound, threshold, percent, num_simulations,\n",
    "                 caseloads, k = 10, repeat = False):\n",
    "\n",
    "        self.age_hier = age_hier\n",
    "        self.age_name = age_name\n",
    "        self.race_hier = race_hier\n",
    "        self.race_name = race_name\n",
    "        self.sex_hier = sex_hier\n",
    "        self.sex_name = sex_name\n",
    "        self.ethnicity_hier = ethnicity_hier\n",
    "        self.ethnicity_name = ethnicity_name\n",
    "        self.census = census\n",
    "        self.county_pop = census.groupby('fips').agg({'counts':'sum'}).sort_index()\n",
    "        self.lb = pop_lower_bound\n",
    "        self.ub = pop_upper_bound\n",
    "        self.threshold = threshold\n",
    "        self.percent = percent\n",
    "        self.num_sims = num_simulations\n",
    "        self.num_cases = caseloads\n",
    "        self.k = k\n",
    "        self.repeat = repeat\n",
    "        \n",
    "    def list_all_policies(self):\n",
    "        \"\"\"\n",
    "        Generate list of tuples including all unique policy generalization combinations\n",
    "        given the age, race, sex, and ethnicity hierarchies.\n",
    "        \"\"\"\n",
    "        ages = list(self.age_hier.keys())\n",
    "        races = list(self.race_hier.keys())\n",
    "        sexes = list(self.sex_hier.keys())\n",
    "        eths = list(test.ethnicity_hier.keys())\n",
    "\n",
    "        all_combinations = list(itertools.product(*[ages,races,sexes,eths]))\n",
    "        combos = pd.DataFrame({'scale':np.array(all_combinations).sum(axis=1)})\n",
    "        self.all_policies = [all_combinations[i] for i in combos.sort_values('scale').index.values]\n",
    "        \n",
    "    def policy_parameters(self, age_idx, race_idx, sex_idx, eth_idx):\n",
    "        \"\"\"\n",
    "        Extract policy name and parameters from hierarchies.\n",
    "        \"\"\"\n",
    "        self.name = self.age_name[age_idx] + \\\n",
    "                    self.race_name[race_idx] + \\\n",
    "                    self.sex_name[sex_idx] + \\\n",
    "                    self.ethnicity_name[eth_idx]\n",
    "        self.params = [self.age_hier[age_idx],\n",
    "                       self.race_hier[race_idx],\n",
    "                       self.sex_hier[sex_idx],\n",
    "                       self.ethnicity_hier[eth_idx]]\n",
    "        \n",
    "    def run_search(self):\n",
    "        \"\"\"\n",
    "        Execute the policy search.\n",
    "        \"\"\"\n",
    "        self.list_all_policies()\n",
    "        self.results = {}\n",
    "        \n",
    "        for num in self.num_cases:\n",
    "\n",
    "            policies = self.all_policies.copy()\n",
    "            acceptable_policies = []\n",
    "\n",
    "            # fix caseload value\n",
    "            fixed_df = pd.DataFrame({'01-01-01':np.repeat(num, len(self.county_pop.index))},\n",
    "                                    index = self.county_pop.index)\n",
    "\n",
    "            # find fips codes for counties that meet total population range\n",
    "            select = (self.county_pop > num) & (self.county_pop > self.lb) & (self.county_pop < self.ub)\n",
    "            fips = np.array(self.county_pop.index[select.counts.values])\n",
    "\n",
    "            while len(policies) > 0:\n",
    "\n",
    "                passed = True\n",
    "\n",
    "                # choose first policy\n",
    "                levels = policies[0]\n",
    "\n",
    "                # generalize per policy\n",
    "                self.policy_parameters(age_idx = levels[0],\n",
    "                                       race_idx = levels[1],\n",
    "                                       sex_idx = levels[2],\n",
    "                                       eth_idx = levels[3])\n",
    "\n",
    "                generalized_census = generalize(self.census[self.census.fips.isin(fips)],\n",
    "                                                ages = self.params[0],\n",
    "                                                races = self.params[1],\n",
    "                                                sexes = self.params[2],\n",
    "                                                ethnicities = self.params[3])\n",
    "\n",
    "                # test policy for each county\n",
    "                for fip in fips:\n",
    "                    test = privacy_risk_estimation_PK(counts = fixed_df.loc[fip,:].to_frame().transpose(),\n",
    "                                                      gen_census = generalized_census.loc[fip,:],\n",
    "                                                      fips = fip,\n",
    "                                                      n_sims = self.num_sims,\n",
    "                                                      k = self.k,\n",
    "                                                      period_size = 1) # period size is set to 1 as results are\n",
    "                                                                       # period size agnostic\n",
    "                    test.run_full_simulation()\n",
    "                    risk = np.percentile(test.PK, self.percent)\n",
    "                    if risk > self.threshold:\n",
    "                        passed = False\n",
    "                        break\n",
    "                        \n",
    "                # if the policy meets the threshold for each county, mark the policy as acceptable and\n",
    "                # remove from consideration for larger caseloads. Otherwise, remove all parent policies\n",
    "                # from consideration for the current caseload.\n",
    "                \n",
    "                if passed:\n",
    "                    acceptable_policies.append(self.name)\n",
    "                    policies = policies[1:]\n",
    "                    \n",
    "                    # remove acceptable policies from consideration for subsequent, larger case count\n",
    "                    # thresholds\n",
    "                    \n",
    "                    if not self.repeat: \n",
    "                        self.all_policies.remove((int(levels[0]),\n",
    "                                             int(levels[1]),\n",
    "                                             int(levels[2]),\n",
    "                                             int(levels[3])))\n",
    "                else:\n",
    "                    keep = []\n",
    "                    for x, y in enumerate(policies):\n",
    "                        if not (y[0] >= levels[0]) & (y[1] >= levels[1]) & \\\n",
    "                                (y[2] >= levels[2]) & (y[3] >= levels[3]):\n",
    "                            keep.append(policies[x])\n",
    "                    policies = keep.copy()\n",
    "\n",
    "            # store results\n",
    "            self.results[num] = acceptable_policies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define the age, race, sex, and ethnicity hierarchies described in the methods section of the manuscript. We also define the naming conventions for the policies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "age_hier = {0:[0,150],\n",
    "            1:[0, 60, 120],\n",
    "            2:[0, 30, 60, 90, 120],\n",
    "            3:[0, 15, 30, 45, 60, 75, 90, 120],\n",
    "            4:[0, 5, 10, 15, 20, 25, 30, 35, 40, 45, 50, 55, 60, 65, 70, 75, 80, 85, 90, 120],\n",
    "            5:False}\n",
    "\n",
    "age_name = {0:'*',\n",
    "            1:'4',\n",
    "            2:'3',\n",
    "            3:'2',\n",
    "            4:'1',\n",
    "            5:'0'}\n",
    "\n",
    "race_hier = {0:[{'all':['w', 'b', 'ai_an', 'a', 'nh_pi', 'other', 'mixed']}],\n",
    "             1:[{'wb':['w','b']}, {'notwb':['ai_an', 'a', 'nh_pi', 'other', 'mixed']}],\n",
    "             2:[{'other':['ai_an', 'nh_pi', 'other', 'mixed']}],\n",
    "             3:None}\n",
    "\n",
    "race_name = {0:'*',\n",
    "             1:'C',\n",
    "             2:'B',\n",
    "             3:'A'}\n",
    "\n",
    "sex_hier = {0:True,\n",
    "            1:False}\n",
    "\n",
    "sex_name = {0:'*',\n",
    "            1:'s'}\n",
    "\n",
    "ethnicity_hier = {0:True,\n",
    "                  1:False}\n",
    "\n",
    "ethnicity_name = {0:'*',\n",
    "                  1:'e'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Smaller county example\n",
    "We run through two examples. We first show the search results for counties with total populations between 20,000 and 30,000 citizens. In our example census data, 9 out of 10 counties fit this criteria."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>counts</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fips</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>22645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>22849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>22858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>23111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>23156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>23292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>23296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>24444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>25582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>66610</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      counts\n",
       "fips        \n",
       "10     22645\n",
       "4      22849\n",
       "8      22858\n",
       "2      23111\n",
       "3      23156\n",
       "9      23292\n",
       "5      23296\n",
       "1      24444\n",
       "7      25582\n",
       "6      66610"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "census.groupby('fips').agg({'counts':'sum'}).sort_values('counts')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thus ,the search will identify policies that meet the threshold in all 9 of these counties. To increase the likelihood the policies will meet a PK10 threshold of 0.01 in practice, we set the percent to 97.5. This means that after the search runs 1,000 Monte Carlo simulations for a unique county, case load, and policy combination, the search will compare the upper bound of the 95% quantile range of the 1,000 simulation outcomes to the threshold. The policy meets the threshold if this upper bound is less than or equal to the threshold. The policy is deemed acceptable for the case load if it meets the threshold for all 9 counties."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 21.6 s, sys: 232 ms, total: 21.8 s\n",
      "Wall time: 21.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "test = dynamic_policy_search_PK(age_hier = age_hier, age_name = age_name,\n",
    "                                race_hier = race_hier, race_name = race_name,\n",
    "                                sex_hier = sex_hier, sex_name = sex_name,\n",
    "                                ethnicity_hier = ethnicity_hier, ethnicity_name = ethnicity_name,\n",
    "                                census = census, pop_lower_bound = 20000, pop_upper_bound = 30000,\n",
    "                                threshold = 0.01, percent = 97.5, num_simulations = 1000, \n",
    "                                caseloads = [10, 11, 50, 75, 150, 300, 500, 750],\n",
    "                                k = 10, repeat = False)\n",
    "\n",
    "test.run_search()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We visualize the search results below. Since repeat was set to false, acceptable policies are exclusively listed under the minimum case load at which they meet the threshold for all 9 counties."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of records in time period: 10\n",
      "Total number supported policies: 0\n",
      "New acceptable policies: []\n",
      "\n",
      "Number of records in time period: 11\n",
      "Total number supported policies: 2\n",
      "New acceptable policies: ['****', '***e']\n",
      "\n",
      "Number of records in time period: 50\n",
      "Total number supported policies: 8\n",
      "New acceptable policies: ['**s*', '*C**', '4***', '4**e', '**se', '*C*e']\n",
      "\n",
      "Number of records in time period: 75\n",
      "Total number supported policies: 10\n",
      "New acceptable policies: ['*B**', '*B*e']\n",
      "\n",
      "Number of records in time period: 150\n",
      "Total number supported policies: 20\n",
      "New acceptable policies: ['4C**', '4*s*', '*Cs*', '4C*e', '*Cse', '*A**', '*Bs*', '4*se', '*Bse', '*A*e']\n",
      "\n",
      "Number of records in time period: 300\n",
      "Total number supported policies: 30\n",
      "New acceptable policies: ['3***', '4B**', '2***', '4Cs*', '3**e', '2**e', '4B*e', '*As*', '4Cse', '*Ase']\n",
      "\n",
      "Number of records in time period: 500\n",
      "Total number supported policies: 43\n",
      "New acceptable policies: ['3*s*', '3C**', '2*s*', '2C**', '1***', '3*se', '3C*e', '4A**', '4Bs*', '2C*e', '2*se', '4A*e', '4Bse']\n",
      "\n",
      "Number of records in time period: 750\n",
      "Total number supported policies: 49\n",
      "New acceptable policies: ['3B**', '4As*', '1**e', '2B**', '3B*e', '2B*e']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "acceptable = 0\n",
    "for key, val in test.results.items():\n",
    "    acceptable += len(val)\n",
    "    print('Number of records in time period:', key)\n",
    "    print('Total number supported policies:', acceptable)\n",
    "    print('New acceptable policies:', val)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Larger county example\n",
    "We repeat the experiment with the same parameters, except now the policy search is applied to the one county in the example data with more than 30,000 residents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.25 s, sys: 25.1 ms, total: 3.28 s\n",
      "Wall time: 3.29 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "test = dynamic_policy_search_PK(age_hier = age_hier, age_name = age_name,\n",
    "                                race_hier = race_hier, race_name = race_name,\n",
    "                                sex_hier = sex_hier, sex_name = sex_name,\n",
    "                                ethnicity_hier = ethnicity_hier, ethnicity_name = ethnicity_name,\n",
    "                                census = census, pop_lower_bound = 30000, pop_upper_bound = 70000,\n",
    "                                threshold = 0.01, percent = 97.5, num_simulations = 1000, \n",
    "                                caseloads = [10, 11, 50, 75, 150, 300, 500, 750],\n",
    "                                k = 10, repeat = False)\n",
    "\n",
    "test.run_search()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of records in time period: 10\n",
      "Total number supported policies: 0\n",
      "New acceptable policies: []\n",
      "\n",
      "Number of records in time period: 11\n",
      "Total number supported policies: 4\n",
      "New acceptable policies: ['****', '***e', '*C**', '*C*e']\n",
      "\n",
      "Number of records in time period: 50\n",
      "Total number supported policies: 8\n",
      "New acceptable policies: ['**s*', '**se', '*Cs*', '*Cse']\n",
      "\n",
      "Number of records in time period: 75\n",
      "Total number supported policies: 12\n",
      "New acceptable policies: ['4***', '4C**', '4**e', '4C*e']\n",
      "\n",
      "Number of records in time period: 150\n",
      "Total number supported policies: 16\n",
      "New acceptable policies: ['4*s*', '4Cs*', '4*se', '4Cse']\n",
      "\n",
      "Number of records in time period: 300\n",
      "Total number supported policies: 20\n",
      "New acceptable policies: ['*B**', '*B*e', '*A**', '*A*e']\n",
      "\n",
      "Number of records in time period: 500\n",
      "Total number supported policies: 36\n",
      "New acceptable policies: ['3***', '3C**', '4B**', '2***', '3**e', '*Bs*', '2C**', '2**e', '3C*e', '4A**', '*Bse', '4B*e', '*As*', '2C*e', '*Ase', '4A*e']\n",
      "\n",
      "Number of records in time period: 750\n",
      "Total number supported policies: 36\n",
      "New acceptable policies: []\n",
      "\n"
     ]
    }
   ],
   "source": [
    "acceptable = 0\n",
    "for key, val in test.results.items():\n",
    "    acceptable += len(val)\n",
    "    print('Number of records in time period:', key)\n",
    "    print('Total number supported policies:', acceptable)\n",
    "    print('New acceptable policies:', val)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, repeat was set to False. We repeat this experiment, setting repeat to True to more exhaustively search the policy space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 8.54 s, sys: 33.6 ms, total: 8.58 s\n",
      "Wall time: 8.59 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "test = dynamic_policy_search_PK(age_hier = age_hier, age_name = age_name,\n",
    "                                race_hier = race_hier, race_name = race_name,\n",
    "                                sex_hier = sex_hier, sex_name = sex_name,\n",
    "                                ethnicity_hier = ethnicity_hier, ethnicity_name = ethnicity_name,\n",
    "                                census = census, pop_lower_bound = 30000, pop_upper_bound = 70000,\n",
    "                                threshold = 0.01, percent = 97.5, num_simulations = 1000, \n",
    "                                caseloads = [10, 11, 50, 75, 150, 300, 500, 750],\n",
    "                                k = 10, repeat = True)\n",
    "\n",
    "test.run_search()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of records in time period: 10\n",
      "Total number supported policies: 0\n",
      "Acceptable policies: []\n",
      "\n",
      "Number of records in time period: 11\n",
      "Total number supported policies: 4\n",
      "Acceptable policies: ['****', '***e', '*C**', '*C*e']\n",
      "\n",
      "Number of records in time period: 50\n",
      "Total number supported policies: 8\n",
      "Acceptable policies: ['****', '***e', '**s*', '*C**', '**se', '*Cs*', '*C*e', '*Cse']\n",
      "\n",
      "Number of records in time period: 75\n",
      "Total number supported policies: 12\n",
      "Acceptable policies: ['****', '***e', '**s*', '*C**', '4***', '4C**', '4**e', '**se', '*Cs*', '*C*e', '4C*e', '*Cse']\n",
      "\n",
      "Number of records in time period: 150\n",
      "Total number supported policies: 16\n",
      "Acceptable policies: ['****', '***e', '**s*', '*C**', '4***', '4C**', '4*s*', '4**e', '**se', '*Cs*', '*C*e', '4Cs*', '4C*e', '*Cse', '4*se', '4Cse']\n",
      "\n",
      "Number of records in time period: 300\n",
      "Total number supported policies: 20\n",
      "Acceptable policies: ['****', '***e', '**s*', '*C**', '4***', '4C**', '4*s*', '4**e', '**se', '*B**', '*Cs*', '*C*e', '4Cs*', '4C*e', '*B*e', '*Cse', '*A**', '4*se', '*A*e', '4Cse']\n",
      "\n",
      "Number of records in time period: 500\n",
      "Total number supported policies: 36\n",
      "Acceptable policies: ['****', '***e', '**s*', '*C**', '4***', '4C**', '4*s*', '4**e', '3***', '**se', '*B**', '*Cs*', '*C*e', '3C**', '4B**', '2***', '4Cs*', '4C*e', '*B*e', '*Cse', '3**e', '*A**', '*Bs*', '4*se', '2C**', '2**e', '3C*e', '4A**', '*Bse', '4B*e', '*A*e', '*As*', '4Cse', '2C*e', '*Ase', '4A*e']\n",
      "\n",
      "Number of records in time period: 750\n",
      "Total number supported policies: 36\n",
      "Acceptable policies: ['****', '***e', '**s*', '*C**', '4***', '4C**', '4*s*', '4**e', '3***', '**se', '*B**', '*Cs*', '*C*e', '3C**', '4B**', '2***', '4Cs*', '4C*e', '*B*e', '*Cse', '3**e', '*A**', '*Bs*', '4*se', '2C**', '2**e', '3C*e', '4A**', '*Bse', '4B*e', '*A*e', '*As*', '4Cse', '2C*e', '*Ase', '4A*e']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for key, val in test.results.items():\n",
    "    print('Number of records in time period:', key)\n",
    "    print('Total number supported policies:', len(val))\n",
    "    print('Acceptable policies:', val)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In these results, we see that once a policy meets the PK10 threshold, the policy always meets the threshold at larger case count values. For this reason, we reduced the search time significantly by allowing the removal of previously supported policies when searching at larger case quantities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
